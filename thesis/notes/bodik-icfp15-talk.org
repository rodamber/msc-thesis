# Check out DARPA BRASS program

# "Alvinization", slide 10:
Lifts code to a higher-level abstraction and then synthesizes from there
"lifting legacy code and reverse engineering"

# Search vs Deduction, slide 13:
Search sidesteps semantics-preserving rewrite rules
correctness by verification, not by construction.
The point is that these invariants are easier to find and synthesize are easier
than the rewrite rules for deduction.
But the search space is too large...

# Trick 1: restrict the space of programs, slide 15:
- DSLs
- Templates
- Holes (SIMD magic constants)

# Trick 2 (algorithmic): inductive synthesis, slide 16:
Inductive Synthesizer: given a search space and a set of inputs that sample it,
find a program that is correct on those inputs
Verifier: ok, we are done, or here's an input where your program is incorrect
with respect to your spec and add it to your set of samples. Every new input
captures a new corner case; greedy approximation of a perfect test suite (where
if your program is correct on those, then it's correct on every input)

# Trick 3: inductive synthesis as SAT solving, slide 17:
given concrete i/o pair x,y, find h such that sketch[h](x) = y

- inverse execution
- pruning (cdcl, Ruben?)
  
# Challenge 1:
- Hill climbing towards a better program
- Prune in the space of behaviors, not programs (ranking?)
  A set of programs defines a much smaller set of behaviors, because there are
  programs that basically do the same thing, so we're effectively reducing the
  search space.
- execute candidates natively (not bit-level interpretation)
- big jumps in the candidate space
- A theory of rewrites (deductive search???)
  
---------------------------------------------------------------------------------

"Specs can be incomplete; you consult a human oracle to resolve ambiguity."
