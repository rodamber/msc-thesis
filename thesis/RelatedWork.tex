\chapter{Related Work}
\label{chapter:relatedWork}

% Note that the reader might not read the document in the order it is presented.

This chapter discusses the state of the art of the field of program synthesis.
Section~\ref{sec:challenges} presents the inherent challenges of the problem,
such as resolving ambiguity or the size of the search space;
section~\ref{sec:specifications} \pdfmarkupcomment[color=yellow]{presents the
various forms that specifications can take}{Huh, ugly.};
section~\ref{sec:applications}
presents applications of the problem; section~\ref{sec:search-techniques}
presents techniques to prune the search space; section~\ref{sec:pbe} refers to
work done specifically in the area of \ac{PBE}.

\section{Challenges}
\label{sec:challenges}

\begin{itemize}
\item Search space
\item User intent
  \item 
\end{itemize}

\section{Specifications}
\label{sec:specifications}

\begin{itemize}
\item syntactic bias, sketches, metasketches (sketch generation), templates, skeleton,
\item   grammar, dsls, holes, SyGuS
\item programming by example, input-output examples/constraints, inductive programming
\item from execution traces
\item another program
\item logical relation
\end{itemize}

\subsection{Sketching}

Introduced in \cite{Solar-Lezama:2008}.

Some specs are difficult to master (tricky or involved, the formalism may be
hard, etc) and/or ``far removed from traditional programming models'' (Solar-Lezama).

Insight is given by incomplete programs which express the high-level structure
of the procedures while leaving missing parts, called holes, for the synthesizer
to fill.

\section{Applications}
\label{sec:applications}

\begin{itemize}
\item flash fill
\item super-optimization
\item reverse engineering
\item data wrangling
\item filling incomplete programs
\end{itemize}

\section{Search Techniques}
\label{sec:search-techniques}

\pdfmargincomment{Ref. is Ras Bodik ICFP15 talk} Derivation (deductive search?)
applies semantics-preserving rewrite rules... correctness by construction.
Search (enumerative search?) sidesteps this, but the program space can be too
large. One way to tackle this issue is to syntactically restrict the space of
valid programs. We can do this by restricting the programs to those expressible
in a small DSL: \pdfmargincomment{Check out more recent research.} Gulwani and
Sumit \cite{Gulwani:2011} used FlashFill to automate string processing in the
context of spreadsheet applications using input-output examples; Cheung et al.
\cite{Cheung:2013} used a subset of SQL to synthesize optimized database-backed
applications; the FlashExtract DSL \cite{Le:2014} includes programs that take
semi-structured text files and a data structure definition as input, and return
an instance of that data structure;.

Another approach is to let the user provide a partial program, hinting the
structure of the intended implementation, while leaving holes for the
synthesizer to fill:

templates \cite{Srivastava:2012},
holes (like SIMD magic constants) \cite{Solar-Lezama:2008}

\ac{CEGIS}, introduced by Solar-Lezama \cite{Solar-Lezama:2008},
\pdfmarkupcomment[color=red]{``which combines the inductive synthesizer with a validation procedure to
automatically generate test inputs and ensure that the generated program
satisfies its specification.''}{Copied from the his abstract.}

\subsection{Deductive Search}
\label{sec:deductive-search}

\pdfmarkupcomment[color=red]{``Deductive systems rely on derivation, but this makes it hard to take advantage
of partial information about the solution.''}{From Solar-Lezama thesis, p.25}

\begin{itemize}
\item deductive search
\item transformation-based search
\item enumerative search (top-down, bottom-up, bidirectional, offline exhaustive enumeration and composition)
\item oracles (validation, correction, programs), CEGIS, OGIS, (universal) distinguishing inputs
\item constraint-based search (component based, sketch generation/completion, solver-aided programming, ILP, )
\item statistical search (machine learning, genetic programming, MCMC, sampling, probabilistic inference)
\item Neural-guided search
\item Graph neural networks
\item PBE VSAs, deduction-based, inverse semantics, type-based, ambiguity, intent
\item Active learning, interaction, distinguishing inputs
\item meta-synthesis, rosette, prose, sketch, solver-aided programming, domain separation
\item ranking: MCMC, VSA, ML, Metasketches
\end{itemize}

\section{Programming by Examples}
\label{sec:pbe}

\pdffreetextcomment{This section needs rewriting.}

\pdfmargincomment{I wonder if most of this paragraph should not be in the
introduction instead.}
\ac{PBE} is an instance of the program synthesis problem where the specification
is given by \ac{IO} examples.
\pdfmarkupcomment[color=yellow]{Examples are generally easier to read and write
than other kinds of specifications, such as logical formulas or program
sketches}{Not entirely correct; it depends on the application}.
Typically they are preferred due to their ease of use, especially by
non-programmers.
However, sometimes it can be cumbersome or even impractical to specify the
examples concretely, particularly if they are too large.
\pdfmargincomment{Add an example here} \ac{PBE} can then be relaxed to allow
incomplete outputs.
On the other hand, \pdfmarkupcomment[color=yellow]{inputs are tipically easier
to come by.}{Why? And is this necessary?}

\begin{itemize}
\item applications (data wrangling [FlashFill, Morpheus])
\end{itemize}

\subsection{Version Space Algebra}

\pdffreetextcomment{The chapter structure might be following too much the survey...}

\pdffreetextcomment{I don't know this should be here, this seems to be
applicable to other kinds of program synthesis problems}

\ac{VSA} is a data structure that allows for an efficient representation of a
very large space of program sets by exploiting sharing among program
subexpressions. \pdfmarkupcomment[color=yellow]{It also allows for efficient
operations on these sets such as:} {list and explain the operations}.

\pdfmargincomment{expand on this}
They were introduced by Lau et al. in \cite{Lau:2000} and applied in ... for ...
In particular, they were used in FlashFill...

% \ac{VSA} is a data structure which allows for a \pdfcomment{on the size of
% what?} polynomial space representation of sets of programs of exponential size.

\subsection{Specialized Search Techniques}
\label{sec:pbe-search-techniques}

\pdfmarkupcomment[color=yellow]{Typically, they fall inside a
\textit{divide-and-conquer} deductive approach. }{rewrite this}


\begin{itemize}
\item inverse semantics (constraint backpropagation) used in FlashFill
(traditionally using \ac{VSA}): backpropagates constraints down the grammar of
the \ac{DSL}; may not be feasible or can be expensive in practice (?);
\item type-theoretic interpretation of \ac{PBE} and refinement types used, resp.,
in Myth and Synquid. Can be very efficient when the \ac{DSL} carries expressive
refinements (when ill-typed terms outnumber the well-typed ones).
\end{itemize}

\subsection{Disambiguation}
\label{sec:resolving-ambiguity}

Examples are, fundamentally, an \textit{under-specification}. There might be
multiple consistent programs, but we must find the \textit{desired} one.

\subsubsection{Ranking}

\pdfmargincomment{rewrite the whole section} By ranking the set of programs
consistent with examples according to their likelihood (better score, more
likely to be the desired program). Requires domain expertise, it is
time-consuming and error-prone, and is fragile because it depends too much on
the underlying \ac{DSL}. \pdfmarkupcomment[color=yellow]{There have been
approaches to define such functions manually} {refs on page 110 of the survey},
but a more automated approach was proposed by Singh and Gulwani in
\cite{Singh:ranking:2015}. There, they present a supervised machine learning
approach for learning a \pdfmarkupcomment[color=yellow]{hierarchical ranking
function }{explain what hierarchical means and their relation to VSAs} which
they applied to \pdfmarkupcomment[color=yellow]{FlashFill}{have we referenced
flash fill before?}. Some challenges of this are:
\begin{itemize}
\item needs large set of labeled training data;
\item needs appropriate machine learning models and cost functions;
  % basically needs ML expertise, duh
\item the ranking function should allow for efficient identification of the
  top-ranked program.
\end{itemize}

\pdfmargincomment{expand on this} A key insight is that in program synthesis it
is sufficient to rank any correct program higher than all incorrect programs.

\subsubsection{Active Learning}

Active learning is an interactive approach between the user and the synthesizer.
Typically, this happens by asking the user for (a small set of) additional
\ac{IO} examples. \pdfmarkupcomment[color=yellow]{Another idea}{verify this},
introduced by Jha et al.\cite{Jha:oracle:2010}, works by finding a \ref{explain
what this is}\textit{distinguishing input} and query the user what the expected
output should be for it. This way it is possible to disambiguate between two
programs whose outputs differ on that particular input.

Other types of active learning exist such as:
\begin{itemize}
\item displaying the program to the user;
\item paraphrasing the program in natural language;
\item accepting negative examples; 
  % isto e algo que nao parece ter sido muito explorado
\end{itemize}

\pdffreetextcomment{expand} Ambiguity resolution may depend a lot on corner case coverage.

\section{Synthesis of Data Transformation Programs}
\label{sec:data-trans-synth}

\pdffreetextcomment{Data Wrangling?}

\section{Other}
\label{sec:other}

\begin{itemize}
\item smt theory of strings
\item SyGuS
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "Thesis"
%%% End:
